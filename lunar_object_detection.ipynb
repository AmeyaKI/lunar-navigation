{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":13263000,"sourceType":"datasetVersion","datasetId":202982},{"sourceId":15989499,"sourceType":"kernelVersion"}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# # This Python 3 environment comes with many helpful analytics libraries installed\n# # It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# # For example, here's several helpful packages to load\n\n# # Input data files are available in the read-only \"../input/\" directory\n# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport shutil\nimport os\n\nimported_dataset_path = '/kaggle/input/artificial-lunar-rocky-landscape-dataset'\ndestination_path = '/kaggle/working/artificial-lunar-rocky-landscape-dataset'\n\nshutil.copytree(imported_dataset_path, destination_path)\nprint(os.listdir(destination_path))\n\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     print(dirname)\n    # for filename in filenames:\n    #     print(os.path.join(dirname, filename))\n\n# # You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# # You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:01:00.300916Z","iopub.execute_input":"2025-11-19T05:01:00.301187Z","iopub.status.idle":"2025-11-19T05:04:59.526225Z","shell.execute_reply.started":"2025-11-19T05:01:00.301167Z","shell.execute_reply":"2025-11-19T05:04:59.525487Z"}},"outputs":[{"name":"stdout","text":"['top200_largerocks_IDs.txt', 'bounding_boxes.csv', 'mismatch_IDs.txt', 'cam_anomaly_IDs.txt', 'shadow_IDs.txt', 'real_moon_images', 'ground_facing_IDs.txt', 'images']\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import torch, torchvision\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn, FasterRCNN_ResNet50_FPN_Weights\nfrom torchvision.models.detection.faster_rcnn import FastRCNNPredictor\nfrom torch.utils.data import DataLoader, random_split, Dataset\nfrom torchvision.transforms import transforms\nfrom torchmetrics.detection import MeanAveragePrecision\nimport torch.optim as optim\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom PIL import Image\nimport os\nfrom tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:25:47.041509Z","iopub.execute_input":"2025-11-19T05:25:47.042250Z","iopub.status.idle":"2025-11-19T05:26:02.394448Z","shell.execute_reply.started":"2025-11-19T05:25:47.042222Z","shell.execute_reply":"2025-11-19T05:26:02.393856Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"Data Preprocessing","metadata":{}},{"cell_type":"code","source":"# creating basic classifier for rock sizes\nclass BasicClassifier():\n    \"\"\"\n    Sorts images into 3 classes based on their area: \n    small_rock (1), medium_rock (2), large_rock (3)\n    \"\"\"\n    \n    def __init__(self, df: pd.DataFrame, img_width=720, img_height=480):\n        self.df = df.copy()\n        self.img_width = img_width\n        self.img_height = img_height\n        \n        # un-normalizing box height/width to calculate absolute area\n        self.df['Area'] = self.df['Length'] * self.df['Height']\n        \n        self.df = self.df.sort_values(by='Area', ascending=True)\n        \n        # split dataset into thirds\n        df_length = len(self.df)\n        self.lower_limit = self.df['Area'].iloc[df_length // 3 - 1] # first third\n        self.middle_limit = self.df['Area'].iloc[2 * df_length // 3 - 1] # second third\n        \n    def classify_df(self):\n        return self.df.apply(\n            lambda row: self.classify_box(\n                box_width = row['Length'],\n                box_height = row['Height']\n            ),\n            axis=1 \n        )\n\n    def classify_box(self, box_width: float, box_height: float):\n        box_area = box_width * box_height\n\n        # categorize rock depending on size\n        if box_area <= 0:\n            return 0 # None\n        elif 0 < box_area <= self.lower_limit:\n            return 1 # Small Rock\n        elif self.lower_limit < box_area <= self.middle_limit:\n            return 2 # Medium Rocks\n        else:\n            return 3 # Large Rock\n\n\n\n\n    # MISC: helpful dataset visualizer functions (below)\n\n    # visualize distribution of bounding box sizes and help determine approx. class sizes\n    def box_size_distr_visualizer(self):\n        print(\"Pre-Filtering Values:\")\n        self.key_value_statistics(self.df['Area'])\n\n        # Remove outliers using 1.5*IQR Rule\n        AreaQ1 = self.df['Area'].quantile(0.25)\n        AreaQ3 = self.df['Area'].quantile(0.75)\n        area_iqr = AreaQ3 - AreaQ1\n        iqr_for_q1 = AreaQ1 - 1.5 * area_iqr\n        iqr_for_q3 = AreaQ3 + 1.5 * area_iqr\n\n        df_cleaned = self.df['Area'][(self.df['Area'] >= iqr_for_q1) & (self.df['Area'] <= iqr_for_q3)]\n        print(\"Post-Filtering Values:\")\n        self.key_value_statistics(df_cleaned)\n        \n        # Visualize dataset\n        custom_bins = list(np.arange(0,10**4, 500))\n        plt.hist(self.df['Area'], bins=custom_bins)\n        plt.title('Area Distribution of Bounding Box Sizes')\n        plt.xlabel('Box Area')\n        plt.ylabel('Frequency')\n        plt.show()\n    \n    # display key statistics for a list/column of values\n    def key_value_statistics(self, values): \n        print(f\"Max: {values.max()}. Min: {values.min()}. Median: {values.median()}. Mean: {values.mean()} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:07.251386Z","iopub.execute_input":"2025-11-19T05:26:07.252087Z","iopub.status.idle":"2025-11-19T05:26:07.261670Z","shell.execute_reply.started":"2025-11-19T05:26:07.252058Z","shell.execute_reply":"2025-11-19T05:26:07.260929Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# RCNN: convert to x_min, y_min, x_max, y_max\ndef convert_to_rcnn(dataset_path: str, df: pd.DataFrame):\n    new_df = pd.DataFrame()\n    \n    new_df['image'] = 'render' + df['Frame'].astype(int).astype(str).str.zfill(4) + '.png' # Image Name: 1 --> 00001\n    new_df['x_min'] = df['TopLeftCornerX'].round(0).astype(int)\n    new_df['y_min'] = df['TopLeftCornerY'].round(0).astype(int)\n    new_df['x_max'] = (df['TopLeftCornerX'] + df['Length']).round(0).astype(int)\n    new_df['y_max'] = (df['TopLeftCornerY'] + df['Height']).round(0).astype(int)\n    \n    classifier = BasicClassifier(df)\n    new_df['class_id'] = classifier.classify_df()\n    \n    return new_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:10.700929Z","iopub.execute_input":"2025-11-19T05:26:10.701514Z","iopub.status.idle":"2025-11-19T05:26:10.706507Z","shell.execute_reply.started":"2025-11-19T05:26:10.701487Z","shell.execute_reply":"2025-11-19T05:26:10.705690Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# remove faulty images from dataset (October Kaggle update)\ndef remove_errors(dataset_path: str, df: pd.DataFrame):\n    # faulty_path = os.path.join(dataset_path, 'faulty_images')\n    txt_files = [i for i in os.listdir(dataset_path) if i.endswith('.txt')]\n    faulty_images = []\n    \n    for txt in txt_files:\n        with open(os.path.join(dataset_path, txt)) as file:\n            for line in file:\n                faulty_images.append(f\"render{line.strip()}.png\")\n                \n    # print(len(faulty_images)) # 773 faulty images exist\n    img_path = os.path.join(dataset_path, 'images/render')\n    \n    # removes faulty images from render folder\n    def delete_images(img_path: str, faulty_images: list):\n        data_images = [img for img in os.listdir(img_path) if img.endswith('.png')]\n        for img in data_images:\n            if img in faulty_images:\n                os.remove(os.path.join(img_path, img))\n\n    # removes rows of faulty images from dataframe\n    def delete_boxes(new_df: pd.DataFrame, faulty_images: list):\n        filtered_df = new_df[~new_df['image'].isin(faulty_images)]\n        return filtered_df\n    \n    delete_images(img_path, faulty_images)\n    filtered_df = delete_boxes(df, faulty_images)\n    return filtered_df\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:11.942314Z","iopub.execute_input":"2025-11-19T05:26:11.943042Z","iopub.status.idle":"2025-11-19T05:26:11.948943Z","shell.execute_reply.started":"2025-11-19T05:26:11.943018Z","shell.execute_reply":"2025-11-19T05:26:11.948047Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset_path = '/kaggle/working/artificial-lunar-rocky-landscape-dataset'\n    \ndf_path = os.path.join(dataset_path, 'bounding_boxes.csv')\ndf = pd.read_csv(df_path)\n\nnew_df = convert_to_rcnn(dataset_path, df)\n\nnew_df = remove_errors(dataset_path, new_df)\n\nnew_df_path = os.path.join(dataset_path, 'rcnn_bounding_boxes_final.csv')\nnew_df.to_csv(new_df_path, index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:13.313903Z","iopub.execute_input":"2025-11-19T05:26:13.314805Z","iopub.status.idle":"2025-11-19T05:26:13.736515Z","shell.execute_reply.started":"2025-11-19T05:26:13.314777Z","shell.execute_reply":"2025-11-19T05:26:13.735922Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# Confirming csv file was added to kaggle/working\nprint(os.listdir(dataset_path))\n\n# verifying df was cleaned\nprint(\"csv\")\nprint(len(df))\nprint(len(new_df))\n\n# verifying image folder was cleaned\nprint(\"Folder\")\nimg_path = os.path.join(dataset_path, 'images/render')\nprint(len(os.listdir(img_path)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:17.416433Z","iopub.execute_input":"2025-11-19T05:26:17.417048Z","iopub.status.idle":"2025-11-19T05:26:17.426408Z","shell.execute_reply.started":"2025-11-19T05:26:17.417023Z","shell.execute_reply":"2025-11-19T05:26:17.425786Z"}},"outputs":[{"name":"stdout","text":"['top200_largerocks_IDs.txt', 'bounding_boxes.csv', 'mismatch_IDs.txt', 'cam_anomaly_IDs.txt', 'shadow_IDs.txt', 'rcnn_bounding_boxes_final.csv', 'real_moon_images', 'ground_facing_IDs.txt', 'images']\ncsv\n18867\n16819\nFolder\n8993\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"class RCNNImageDataset(Dataset):\n    IMAGE_WIDTH = 720\n    IMAGE_HEIGHT = 480\n    SCALE = 600 / IMAGE_HEIGHT\n    def __init__(self, dataset_path, transforms=None):\n        self.dataset_path = dataset_path\n        self.img_path = os.path.join(dataset_path, 'images/render') # directory to images folder\n        self.boxes_path = os.path.join(dataset_path, 'rcnn_bounding_boxes_final.csv') # directory to csv\n        \n        self.df = pd.read_csv(self.boxes_path) # bounding boxes df\n        self.images = sorted(self.df['image'].unique()) # unique image name values: render0001.jpg, render9771.jpg\n        \n        self.transforms = transforms # transforms (if applicable)\n                \n    def __len__(self):\n        return len(self.images)        \n                \n    def __getitem__(self, index):\n        img_name = self.images[index]\n        img_path = os.path.join(self.img_path, f\"{img_name}\")\n        image = Image.open(img_path).convert('RGB')\n        \n        # Find bounding boxes and class_id for selected image\n        img_df = self.df[self.df['image'] == img_name]\n        boxes = img_df[['x_min', 'y_min', 'x_max', 'y_max']].values\n        class_id = img_df['class_id'].values\n        \n\n        # transforms + Manual resizing\n\n        # width, height = image.size # 720, 480\n        # scaler = 7/15 # 336 x 224\n        new_width = int(self.IMAGE_WIDTH * self.SCALE)\n        new_height = int(self.IMAGE_HEIGHT * self.SCALE)\n        \n        image = image.resize((new_width, new_height))\n        boxes = boxes * self.SCALE\n        \n        if self.transforms:\n            image = self.transforms(image) # turns image into tensor\n            \n        # converts boxes and class_id to tensors\n        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n        labels = torch.as_tensor(class_id, dtype=torch.int64)       \n        \n        # calculates area and iscrowd pytorch variables\n        area = (boxes[:, 2] - boxes[:, 0]) * (boxes[:, 3] - boxes[:, 1])\n        iscrowd = torch.zeros((len(img_df),), dtype=torch.int64)\n        \n        target = {\n            \"boxes\": boxes,\n            \"labels\": labels,\n            \"image_id\": torch.tensor([index]),\n            \"area\": area,\n            \"iscrowd\": iscrowd\n        }\n        \n        # return image and target dict\n        return image, target","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:26.912785Z","iopub.execute_input":"2025-11-19T05:26:26.913495Z","iopub.status.idle":"2025-11-19T05:26:26.921620Z","shell.execute_reply.started":"2025-11-19T05:26:26.913467Z","shell.execute_reply":"2025-11-19T05:26:26.920728Z"}},"outputs":[],"execution_count":9},{"cell_type":"markdown","source":"Model Set Up!","metadata":{}},{"cell_type":"code","source":"# Model: PyTorch Faster R-CNN \n\ntorch.backends.cudnn.benchmark = True\ntorch.backends.cudnn.enabled = True\n\n# Use CUDA in Kaggle\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using: {device}\")\n\n# Data Processing\n# dataset_path already defined\n\ntransform = transforms.Compose([\n    transforms.ToTensor()\n])\n\ndataset = RCNNImageDataset(dataset_path, transform)\n\n# Train: 70%, Val: 15%, Test: 15%\ntrain_size = int(0.7 * len(dataset))\nval_size = int(0.15 * len(dataset))\ntest_size = len(dataset) - train_size - val_size\n\ntrain_dataset, val_dataset, test_dataset = random_split(\n    dataset, [train_size, val_size, test_size]\n)\n\ndef collate(batch):\n    return tuple(zip(*batch))\n\nNUM_WORKERS = 2\nBATCH_SIZE = 4\nPREFETCH = 4\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, \n                          num_workers=NUM_WORKERS,pin_memory=True, \n                          persistent_workers=False, collate_fn=collate, \n                          prefetch_factor=PREFETCH) \nval_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, \n                        num_workers=NUM_WORKERS, pin_memory=True, \n                        persistent_workers=False, collate_fn=collate, \n                        prefetch_factor=PREFETCH)\ntest_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, \n                         num_workers=NUM_WORKERS, pin_memory=True, \n                         persistent_workers=False, collate_fn=collate, \n                         prefetch_factor=PREFETCH)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:43.658353Z","iopub.execute_input":"2025-11-19T05:26:43.658614Z","iopub.status.idle":"2025-11-19T05:26:43.753441Z","shell.execute_reply.started":"2025-11-19T05:26:43.658597Z","shell.execute_reply":"2025-11-19T05:26:43.752668Z"}},"outputs":[{"name":"stdout","text":"Using: cuda\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# Model Construction\nmodel_weights=FasterRCNN_ResNet50_FPN_Weights.DEFAULT\nmodel = fasterrcnn_resnet50_fpn(weights=model_weights)\nnum_classes = 4 # 3 rock sizes + background\nin_features = model.roi_heads.box_predictor.cls_score.in_features # type: ignore\n\nmodel.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n\nmodel.to(device)\n\n# print(model) # List out RCNN layers\n# loss_function = built-in, call while training\n\nparameters = [p for p in model.parameters() if p.requires_grad]\noptimizer = optim.AdamW(\n    parameters,\n    lr=2e-4,\n    weight_decay=0.0005\n)\n# optimizer = optim.SGD(\n#     parameters,\n#     lr=0.005,\n#     momentum=0.9,\n#     weight_decay=0.0005\n# )\nscaler = torch.amp.GradScaler(device, enabled=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:45.988239Z","iopub.execute_input":"2025-11-19T05:26:45.988528Z","iopub.status.idle":"2025-11-19T05:26:48.144433Z","shell.execute_reply.started":"2025-11-19T05:26:45.988507Z","shell.execute_reply":"2025-11-19T05:26:48.143852Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_coco-258fb6c6.pth\n100%|██████████| 160M/160M [00:00<00:00, 218MB/s] \n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"def train_epoch(model, train_loader, optimizer, device, epoch, print_freq=100, accum_steps=1):\n    model.train() # set model to train mode\n    running_loss = 0.0\n    \n    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader), desc=f\"Epoch {epoch}\")\n\n    optimizer.zero_grad()\n    for batch_index, (images, targets) in progress_bar:\n        # Move images/targets to device\n        images = [img.to(device) for img in images]\n        targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n\n        # Forward pass\n        with torch.amp.autocast('cuda'):\n            loss_dict = model(images, targets)\n            losses = sum(loss_dict.values()) / accum_steps\n        # loss_dict = model(images, targets)\n        # losses = sum((loss for loss in loss_dict.values() if torch.is_tensor(loss)), torch.tensor(0.0, device=device))\n        \n        # Backward pass\n        scaler.scale(losses).backward()\n        # losses.backward()\n        # optimizer.step()\n        \n        # Update metrics\n        if (batch_index + 1) % accum_steps == 0:\n            scaler.step(optimizer)\n            scaler.update()\n            optimizer.zero_grad()\n            \n        batch_loss = losses.item() * accum_steps\n        running_loss += batch_loss\n        progress_bar.set_postfix(loss=batch_loss)\n\n        if (batch_index + 1) % print_freq == 0:\n            avg_loss = running_loss / print_freq\n            print(f\"[Batch {batch_index + 1}/{len(train_loader)}] \"\n                  f\"Loss: {avg_loss:.4f}\")\n            running_loss = 0.0 # reset running loss every {print_freq} batches\n            \n    return running_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:52.671368Z","iopub.execute_input":"2025-11-19T05:26:52.671991Z","iopub.status.idle":"2025-11-19T05:26:52.678713Z","shell.execute_reply.started":"2025-11-19T05:26:52.671966Z","shell.execute_reply":"2025-11-19T05:26:52.677857Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"def evaluate(model, test_loader, device):\n    model.eval() # swithc to eval\n    metric = MeanAveragePrecision() # mAP\n    # total_loss = 0\n    \n    with torch.no_grad():\n        for images, targets in val_loader:\n            images = [img.to(device) for img in images]\n            targets = [{k: v.to(device) for k, v in t.items()} for t in targets]\n            \n            # no val loss in model.eval() mode\n            # with torch.amp.autocast('cuda'):\n            #     loss_dict = model(images, targets)\n            #     losses = sum(loss_dict.values())\n            #     total_loss += losses.item()\n            # loss_dict = model(images, targets)\n            # total_loss += sum(loss.item() if torch.is_tensor(loss) else float(loss) for loss in loss_dict.values())\n    \n            # get mAP predictions\n            preds = model(images)\n            metric.update(preds, targets)\n            \n    # avg_loss = total_loss / len(test_loader)\n    metrics = metric.compute()\n\n    return metrics # avg_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:26:55.874041Z","iopub.execute_input":"2025-11-19T05:26:55.874335Z","iopub.status.idle":"2025-11-19T05:26:55.879416Z","shell.execute_reply.started":"2025-11-19T05:26:55.874313Z","shell.execute_reply":"2025-11-19T05:26:55.878773Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"num_epochs = 10\nbest_mAP = 0.0\n\nprint(\"==========Training==========\")\nfor epoch in range(1, num_epochs+1):\n    print(f\"\\n==========Epoch: {epoch}==========\")\n    \n    # Training\n    train_loss = train_epoch(model, train_loader, optimizer, device, epoch)\n    \n    # Validating\n    val_metrics = evaluate(model, val_loader, device)\n    # print(f\"Validation Loss: {val_loss:.4f}\")\n    print(\"Validation Metrics\")\n    print(f\"mAP: {val_metrics['map']:.4f} | mAP_50: {val_metrics['map_50']:.4f} | mAP_75: {val_metrics['map_75']:.4f}\")\n\n    if val_metrics['map'] > best_mAP:\n        best_mAP = val_metrics['map']\n        torch.save(model.state_dict(), \"best_model.pth\")\n        \n        \n# Testing\nprint(\"\\n==========Testing==========\")\ntest_metrics = evaluate(model, test_loader, device)\n# print(f\"Test Loss: {val_loss:.4f}\")\nprint(f\"mAP: {test_metrics['map']:.4f} | mAP_50: {test_metrics['map_50']:.4f} | mAP_75: {test_metrics['map_75']:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T05:28:16.618511Z","iopub.execute_input":"2025-11-19T05:28:16.618806Z","iopub.status.idle":"2025-11-19T07:22:05.508637Z","shell.execute_reply.started":"2025-11-19T05:28:16.618778Z","shell.execute_reply":"2025-11-19T07:22:05.507734Z"}},"outputs":[{"name":"stdout","text":"==========Training==========\n\n==========Epoch: 1==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  10%|█         | 100/994 [01:02<09:16,  1.61it/s, loss=0.283]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.5135\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  20%|██        | 200/994 [02:05<08:15,  1.60it/s, loss=0.34] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.4020\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  30%|███       | 300/994 [03:07<07:12,  1.60it/s, loss=0.409]","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.4151\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.344]","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.3919\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  50%|█████     | 500/994 [05:12<05:07,  1.60it/s, loss=0.362]","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.3667\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.213] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.3833\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  70%|███████   | 700/994 [07:16<03:03,  1.60it/s, loss=0.411]","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.3647\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  80%|████████  | 800/994 [08:19<02:00,  1.61it/s, loss=0.232]","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.3975\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.186]","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.3492\n","output_type":"stream"},{"name":"stderr","text":"Epoch 1: 100%|██████████| 994/994 [10:32<00:00,  1.57it/s, loss=0.313]\n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.3979 | mAP_50: 0.6649 | mAP_75: 0.4285\n\n==========Epoch: 2==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  10%|█         | 100/994 [01:02<09:17,  1.60it/s, loss=0.226]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.3411\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  20%|██        | 200/994 [02:05<08:14,  1.60it/s, loss=0.47] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.3582\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  30%|███       | 300/994 [03:07<07:12,  1.60it/s, loss=0.304]","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.3478\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.19]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.3258\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  50%|█████     | 500/994 [05:12<05:07,  1.61it/s, loss=0.522]","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.3408\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.376]","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.3079\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  70%|███████   | 700/994 [07:16<03:04,  1.60it/s, loss=0.434] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.3257\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  80%|████████  | 800/994 [08:19<02:00,  1.61it/s, loss=0.3]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.3342\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2:  91%|█████████ | 900/994 [09:21<00:58,  1.61it/s, loss=0.436]","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.3212\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2: 100%|██████████| 994/994 [10:19<00:00,  1.60it/s, loss=0.266]\n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4323 | mAP_50: 0.7097 | mAP_75: 0.4766\n\n==========Epoch: 3==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  10%|█         | 100/994 [01:02<09:16,  1.61it/s, loss=0.401]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.2851\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  20%|██        | 200/994 [02:04<08:17,  1.60it/s, loss=0.636] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.3098\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  30%|███       | 300/994 [03:07<07:13,  1.60it/s, loss=0.109]","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.2806\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.128] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.2739\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  50%|█████     | 500/994 [05:12<05:08,  1.60it/s, loss=0.208]","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.2992\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  60%|██████    | 600/994 [06:14<04:06,  1.60it/s, loss=0.218]","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.3103\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  70%|███████   | 700/994 [07:16<03:03,  1.60it/s, loss=0.212] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.2799\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  80%|████████  | 800/994 [08:19<02:01,  1.60it/s, loss=0.567] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.3124\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.199]","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.2978\n","output_type":"stream"},{"name":"stderr","text":"Epoch 3: 100%|██████████| 994/994 [10:19<00:00,  1.60it/s, loss=0.174]\n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4620 | mAP_50: 0.7398 | mAP_75: 0.5178\n\n==========Epoch: 4==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  10%|█         | 100/994 [01:02<09:18,  1.60it/s, loss=0.167]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.2774\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  20%|██        | 200/994 [02:05<08:14,  1.60it/s, loss=0.164]","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.2437\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  30%|███       | 300/994 [03:07<07:13,  1.60it/s, loss=0.409] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.2895\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.192] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.2521\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  50%|█████     | 500/994 [05:12<05:08,  1.60it/s, loss=0.3]   ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.2599\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  60%|██████    | 600/994 [06:14<04:05,  1.60it/s, loss=0.23]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.2504\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  70%|███████   | 700/994 [07:17<03:02,  1.61it/s, loss=0.223] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.2645\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  80%|████████  | 800/994 [08:19<02:00,  1.61it/s, loss=0.188] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.2765\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.363] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.2924\n","output_type":"stream"},{"name":"stderr","text":"Epoch 4: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.275] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4614 | mAP_50: 0.7394 | mAP_75: 0.5115\n\n==========Epoch: 5==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  10%|█         | 100/994 [01:02<09:17,  1.60it/s, loss=0.144]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.2096\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  20%|██        | 200/994 [02:04<08:15,  1.60it/s, loss=0.143] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.2269\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  30%|███       | 300/994 [03:07<07:12,  1.60it/s, loss=0.271] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.2352\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  40%|████      | 400/994 [04:09<06:10,  1.60it/s, loss=0.133] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.2471\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  50%|█████     | 500/994 [05:11<05:08,  1.60it/s, loss=0.146] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.2410\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.207] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.2580\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  70%|███████   | 700/994 [07:16<03:03,  1.60it/s, loss=0.0961]","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.2301\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  80%|████████  | 800/994 [08:19<02:01,  1.60it/s, loss=0.293] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.2565\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.191] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.2335\n","output_type":"stream"},{"name":"stderr","text":"Epoch 5: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.34] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4591 | mAP_50: 0.7340 | mAP_75: 0.5116\n\n==========Epoch: 6==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  10%|█         | 100/994 [01:02<09:16,  1.61it/s, loss=0.184]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.1992\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  20%|██        | 200/994 [02:04<08:14,  1.61it/s, loss=0.226] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.2116\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  30%|███       | 300/994 [03:07<07:12,  1.60it/s, loss=0.147] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.2107\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  40%|████      | 400/994 [04:09<06:13,  1.59it/s, loss=0.181] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.2030\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  50%|█████     | 500/994 [05:12<05:08,  1.60it/s, loss=0.106] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.2138\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  60%|██████    | 600/994 [06:14<04:05,  1.60it/s, loss=0.381] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.2244\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  70%|███████   | 700/994 [07:17<03:03,  1.60it/s, loss=0.282] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.2216\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  80%|████████  | 800/994 [08:19<02:00,  1.60it/s, loss=0.272]","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.2419\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.14]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.2359\n","output_type":"stream"},{"name":"stderr","text":"Epoch 6: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.316] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4531 | mAP_50: 0.7183 | mAP_75: 0.5076\n\n==========Epoch: 7==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  10%|█         | 100/994 [01:02<09:16,  1.61it/s, loss=0.134]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.1849\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  20%|██        | 200/994 [02:04<08:15,  1.60it/s, loss=0.242] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.1925\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  30%|███       | 300/994 [03:07<07:12,  1.61it/s, loss=0.102] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.1952\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.275] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.2023\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  50%|█████     | 500/994 [05:12<05:07,  1.61it/s, loss=0.118] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.1917\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.191] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.2083\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  70%|███████   | 700/994 [07:16<03:03,  1.61it/s, loss=0.165] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.2003\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  80%|████████  | 800/994 [08:19<02:01,  1.60it/s, loss=0.221] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.2154\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.161] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.2090\n","output_type":"stream"},{"name":"stderr","text":"Epoch 7: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.294] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4616 | mAP_50: 0.7223 | mAP_75: 0.5166\n\n==========Epoch: 8==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  10%|█         | 100/994 [01:02<09:17,  1.60it/s, loss=0.192]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.1827\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  20%|██        | 200/994 [02:05<08:15,  1.60it/s, loss=0.192] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.1921\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  30%|███       | 300/994 [03:07<07:13,  1.60it/s, loss=0.17]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.1700\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  40%|████      | 400/994 [04:09<06:10,  1.60it/s, loss=0.154] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.1894\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  50%|█████     | 500/994 [05:12<05:09,  1.60it/s, loss=0.278] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.1989\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.191] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.1915\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  70%|███████   | 700/994 [07:17<03:02,  1.61it/s, loss=0.17]  ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.1819\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  80%|████████  | 800/994 [08:19<02:01,  1.60it/s, loss=0.335] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.2014\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8:  91%|█████████ | 900/994 [09:22<00:58,  1.60it/s, loss=0.165] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.1783\n","output_type":"stream"},{"name":"stderr","text":"Epoch 8: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.143] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4621 | mAP_50: 0.7220 | mAP_75: 0.5276\n\n==========Epoch: 9==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  10%|█         | 100/994 [01:02<09:18,  1.60it/s, loss=0.231]","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.1664\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  20%|██        | 200/994 [02:05<08:15,  1.60it/s, loss=0.132] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.1633\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  30%|███       | 300/994 [03:07<07:12,  1.60it/s, loss=0.133] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.1658\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  40%|████      | 400/994 [04:09<06:09,  1.61it/s, loss=0.317] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.1780\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  50%|█████     | 500/994 [05:12<05:07,  1.61it/s, loss=0.171] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.1840\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  60%|██████    | 600/994 [06:14<04:05,  1.60it/s, loss=0.243] ","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.1754\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  70%|███████   | 700/994 [07:16<03:03,  1.60it/s, loss=0.144] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.1910\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  80%|████████  | 800/994 [08:19<02:01,  1.60it/s, loss=0.151] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.1820\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.185] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.1698\n","output_type":"stream"},{"name":"stderr","text":"Epoch 9: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.132] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4535 | mAP_50: 0.7098 | mAP_75: 0.5173\n\n==========Epoch: 10==========\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  10%|█         | 100/994 [01:02<09:19,  1.60it/s, loss=0.23] ","output_type":"stream"},{"name":"stdout","text":"[Batch 100/994] Loss: 0.1553\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  20%|██        | 200/994 [02:05<08:16,  1.60it/s, loss=0.101] ","output_type":"stream"},{"name":"stdout","text":"[Batch 200/994] Loss: 0.1542\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  30%|███       | 300/994 [03:07<07:13,  1.60it/s, loss=0.103] ","output_type":"stream"},{"name":"stdout","text":"[Batch 300/994] Loss: 0.1504\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  40%|████      | 400/994 [04:09<06:10,  1.60it/s, loss=0.121] ","output_type":"stream"},{"name":"stdout","text":"[Batch 400/994] Loss: 0.1492\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  50%|█████     | 500/994 [05:12<05:08,  1.60it/s, loss=0.177] ","output_type":"stream"},{"name":"stdout","text":"[Batch 500/994] Loss: 0.1704\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  60%|██████    | 600/994 [06:14<04:05,  1.61it/s, loss=0.0774]","output_type":"stream"},{"name":"stdout","text":"[Batch 600/994] Loss: 0.1768\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  70%|███████   | 700/994 [07:16<03:03,  1.60it/s, loss=0.311] ","output_type":"stream"},{"name":"stdout","text":"[Batch 700/994] Loss: 0.1592\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  80%|████████  | 800/994 [08:19<02:00,  1.61it/s, loss=0.163] ","output_type":"stream"},{"name":"stdout","text":"[Batch 800/994] Loss: 0.1658\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10:  91%|█████████ | 900/994 [09:21<00:58,  1.60it/s, loss=0.143] ","output_type":"stream"},{"name":"stdout","text":"[Batch 900/994] Loss: 0.1646\n","output_type":"stream"},{"name":"stderr","text":"Epoch 10: 100%|██████████| 994/994 [10:20<00:00,  1.60it/s, loss=0.168] \n","output_type":"stream"},{"name":"stdout","text":"Validation Metrics\nmAP: 0.4506 | mAP_50: 0.7045 | mAP_75: 0.5086\n\n==========Testing==========\nmAP: 0.4506 | mAP_50: 0.7045 | mAP_75: 0.5086\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# meetrics decreasing man .... cuz the classes are shittt\n# EDIT THE CLASSES\n\n\n# Later add craters and other luanr objects","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-19T07:39:03.333595Z","iopub.execute_input":"2025-11-19T07:39:03.334202Z","iopub.status.idle":"2025-11-19T07:39:03.337552Z","shell.execute_reply.started":"2025-11-19T07:39:03.334161Z","shell.execute_reply":"2025-11-19T07:39:03.336724Z"}},"outputs":[],"execution_count":17}]}